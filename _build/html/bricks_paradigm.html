

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Paradigms &#8212; Deep Learning 101 for Audio-based MIR</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'bricks_paradigm';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="About the authors" href="biography.html" />
    <link rel="prev" title="Architectures" href="bricks_architecture.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="front.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/wave.png" class="logo__image only-light" alt="Deep Learning 101 for Audio-based MIR - Home"/>
    <script>document.write(`<img src="_static/wave.png" class="logo__image only-dark" alt="Deep Learning 101 for Audio-based MIR - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="front.html">
                    Deep Learning 101 for Audio-based MIR
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Abstract</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="abstract.html">Abstract</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="intro.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="intro_dataset.html">Datasets .hdf5/.pyjama</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_pytorch.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_lightining.html">TorchLightning training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebook.html">Notebooks in Colab</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tasks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="task_musiccontent.html">Music Audio Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="task_multipitchestimation.html">Multi-Pitch-Estimation (MPE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_coverdetection.html">Cover Song Identification (CSI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_autotagging_frontend.html">Auto-Tagging (front-ends)</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_autotagging_ssl.html">Auto-Tagging (self-supervised-learning)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="task_musicprocessing.html">Music Audio Processing</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="task_sourceseparation.html">Source Separation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="task_musicgeneration.html">Musical Audio Generation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_basics.html">Basics of Generative Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_early.html">Early Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_auto.html">Autoregressive Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_diff.html">Generation with Latent Diffusion</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning Bricks</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bricks_input.html">Inputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_frontend.html">Front-ends</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_projection.html">Projections</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_bottleneck.html">Bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_architecture.html">Architectures</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Paradigms</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="biography.html">About the authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibiography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fbricks_paradigm.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/bricks_paradigm.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Paradigms</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised">Supervised</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#self-supervised">Self-supervised</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised">Unsupervised</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metric-learning">Metric Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#triplet-loss">Triplet Loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#triplet-mining">Triplet Mining</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoder-decoder">Encoder-Decoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-models">Diffusion Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-adversarial-networks">Generative Adversarial Networks</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="paradigms">
<h1>Paradigms<a class="headerlink" href="#paradigms" title="Permalink to this heading">#</a></h1>
<p><img alt="top" src="_images/top.png" /></p>
<p>We denote by <code class="docutils literal notranslate"><span class="pre">paradigm</span></code> the overall problem that is used to train a neural network: <em>such as supervised, metric-learning, self-supervised, adversarial, encoder-decoder, …</em></p>
<section id="supervised">
<span id="lab-supervised"></span><h2>Supervised<a class="headerlink" href="#supervised" title="Permalink to this heading">#</a></h2>
<p>Supervised learning is the most standard paradigm in machine learning, hence in deep learning, in which <mark>one has access to both input data <span class="math notranslate nohighlight">\(X\)</span> and the corresponding ground-truth <span class="math notranslate nohighlight">\(y\)</span></mark>.</p>
<p>The goal is then to define a function <span class="math notranslate nohighlight">\(f\)</span> (a specific neural network architecture) and optimize its parameters <span class="math notranslate nohighlight">\(\theta\)</span> such that <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}=f_{\theta}(\mathbf{x})\)</span> best approximates <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>.
This is done by defining a loss <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> associated to the approximation of <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> by <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}\)</span>.
Such a loss can be</p>
<ul class="simple">
<li><p>binary cross entropy (for binary classification problems, i.e. <span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span>, or multi-label problems i.e. <span class="math notranslate nohighlight">\(\mathbf{y} \in \{0,1\}^C\)</span>,</p></li>
<li><p>categorical cross entropy (for multi-class problem, i.e. <span class="math notranslate nohighlight">\(y \in \{0,\ldots, C-1\}\)</span>)</p></li>
<li><p>mean square error (for regression problems, i.e. <span class="math notranslate nohighlight">\(y \in \mathbb{R}\)</span>)</p></li>
</ul>
<p>Since we do not have access to the distribution <span class="math notranslate nohighlight">\(p(\mathbf{x},\mathbf{y})\)</span> but only to samples of it <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{y}^{(i)} \sim p(\mathbf{x},\mathbf{y})\)</span>, we <strong>empirically minimize the loss/risk</strong> for a set of training examples <span class="math notranslate nohighlight">\((\mathbf{x}^{(i)}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{y}^{(i)})\)</span>:</p>
<div class="math notranslate nohighlight">
\[\theta^* = \arg\min_{\theta} \sum_{i=0}^{I-1} \mathcal{L}(f_{\theta}(\mathbf{x}^{(i)}), \mathbf{y}^{(i)})\]</div>
<p>This minimization is usually done using one type of Stochastic Gradient Descent (SGD, Momentum, AdaGrad, AdaDelta, ADAM) and using various cardinality for <span class="math notranslate nohighlight">\(I\)</span> (stochastic, mini-batch, batch GD).</p>
</section>
<section id="self-supervised">
<span id="lab-ssl"></span><h2>Self-supervised<a class="headerlink" href="#self-supervised" title="Permalink to this heading">#</a></h2>
<p>While in supervised learning there is a clear input/target distinction (and both are available), in the self-supervised paradigm, “targets” are typically created from the input data directly.
This can mean to predict the next token in a sequence (the current, popular way of training Large Language Models), to corrupt or mask parts of the input or to augment the input with domain-specific transformations.
Such manipulations or selective predictions sometimes require domain knowledge, injected by domain-informed procedures during training.
This results in data representations that represent specific properties and are invariant to others.
In audio, one could augment signals by changing the volume to obtain representations that are volume-invariant.</p>
</section>
<section id="unsupervised">
<span id="lab-usl"></span><h2>Unsupervised<a class="headerlink" href="#unsupervised" title="Permalink to this heading">#</a></h2>
<p>Unsupervised approaches aim to learn correlations in data without the injection of any (domain-)knowledge.
This results in (typically lower-dimensional) latent spaces with high variance for input dimensions that are correlated.
For example, in music, unsupervised training could result in a latent space that puts samples close when their tonality is close in the circle of fifth <span id="id1">[<a class="reference internal" href="bibiography.html#id3" title="Carlos Eduardo Cancino Chacón, Stefan Lattner, and Maarten Grachten. Developing tonal perception through unsupervised learning. In ISMIR, 195–200. 2014.">ChaconLG14</a>]</span>.</p>
</section>
<section id="metric-learning">
<span id="lab-metric-learning"></span><h2>Metric Learning<a class="headerlink" href="#metric-learning" title="Permalink to this heading">#</a></h2>
<p>Metric learning is a type of machine learning technique focused on <mark>learning a distance function or similarity measure between data points</mark>.
The goal is to <mark>map input data into a space where</mark></p>
<ul class="simple">
<li><p>similar examples are close together and</p></li>
<li><p>dissimilar examples are far apart, based on a certain metric (e.g., Euclidean distance).</p></li>
</ul>
<p>There exist several type of supervision to achieve this</p>
<ul class="simple">
<li><p><strong>Class</strong> labels: <span class="math notranslate nohighlight">\((\mathbf{x},\mathbf{y})\)</span></p></li>
<li><p><strong>Pairwise</strong> similarity/dissimilarity: <span class="math notranslate nohighlight">\((\mathbf{x}^{(1)},\mathbf{x}^{(2)},\pm)\)</span></p></li>
<li><p><strong>Relative</strong> comparisons (triplet): <span class="math notranslate nohighlight">\((\mathbf{x}^{(1)}, \mathbf{x}^{(2)},\mathbf{x}^{(3)}) \Rightarrow d(\mathbf{x}^{(1)},\mathbf{x}^{(2)}) &lt; d(\mathbf{x}^{(1)},\mathbf{x}^{(3)})\)</span></p></li>
</ul>
<p>There exist many algorithm to train such a model such as</p>
<ul class="simple">
<li><p><mark>Contrastive Loss</mark> <span id="id2">[<a class="reference internal" href="bibiography.html#id71" title="Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2006), 17-22 June 2006, New York, NY, USA, 1735–1742. IEEE Computer Society, 2006. URL: https://doi.org/10.1109/CVPR.2006.100, doi:10.1109/CVPR.2006.100.">HCL06</a>]</span> in which we optimize in turns (but not jointly) the model to minimize a distance for similar pairs and maximize (up to a margin) it for dissimilar pairs</p></li>
<li><p><mark>Triplet Loss</mark> <span id="id3">[<a class="reference internal" href="bibiography.html#id70" title="Elad Hoffer and Nir Ailon. Deep metric learning using triplet network. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings. 2015. URL: http://arxiv.org/abs/1412.6622.">HA15</a>]</span> see below</p></li>
</ul>
<p>The triplet loss can be extended to the multiple-loss with close relationship with Contrastive Learning (InfoNCE, NT-Xent losses).</p>
<p>Fore more details, see the very good tutorial <a class="reference external" href="https://github.com/bmcfee/ismir2020-metric-learning">“Metric Learning for Music Information Retrieval” by Brian McFee, Jongpil Lee and Juhan Nam</a></p>
<section id="triplet-loss">
<span id="lab-triplet"></span><h3>Triplet Loss<a class="headerlink" href="#triplet-loss" title="Permalink to this heading">#</a></h3>
<p>The goal is to <mark>train a network <span class="math notranslate nohighlight">\(f_{\theta}\)</span></mark> such that the <mark>projections</mark> of <span class="math notranslate nohighlight">\(\mathbf{x}_A\)</span> (an <strong>anchor</strong>), <span class="math notranslate nohighlight">\(\mathbf{x}_P\)</span> (a <strong>positive</strong> we consider close), <span class="math notranslate nohighlight">\(\mathbf{x}_N\)</span> (a <strong>negative</strong> we consider distant),
satisfy the following triplet constraint:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
d( f_{\theta}(\mathbf{x}_A), f_{\theta}(\mathbf{x}_P) ) + \alpha &amp;&lt; d(f_{\theta}(\mathbf{x}_A), f_{\theta}(\mathbf{x}_N)) \\
d_{AP} + \alpha &amp;&lt; d_{AN}
\end{align}
\end{split}\]</div>
<p>In other words, we want <span class="math notranslate nohighlight">\(d_{AP}\)</span> to be smaller by a <mark>margin</mark> <span class="math notranslate nohighlight">\(\alpha\)</span> than <span class="math notranslate nohighlight">\(d_{AN}\)</span></p>
<p>We solve this by minimizing the so-called “triplet-loss”:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L} = \max(d_{AP} + \alpha - d_{AN},0)\]</div>
<p><em>Note: It is usual to L2-normalized the output of <span class="math notranslate nohighlight">\(f_{\theta}\)</span> (which then lives in the unit-hypersphere) to facilitate the setting of the <span class="math notranslate nohighlight">\(\alpha\)</span> value.</em></p>
<p><img alt="triplet-loss" src="_images/brick_triplet.png" /><br />
<strong>Figure</strong>
<em>Triplet Loss, bringing A and P closer and A and N further appart; image source: <a class="reference external" href="https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905">Link</a></em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">dist_pos</span> <span class="o">+</span> <span class="n">param_d</span><span class="o">.</span><span class="n">margin</span> <span class="o">-</span> <span class="n">dist_neg</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="triplet-mining">
<span id="lab-tripletmining"></span><h3>Triplet Mining<a class="headerlink" href="#triplet-mining" title="Permalink to this heading">#</a></h3>
<p>Triplet mining is the process of <mark>selecting the triplets</mark> for training using the triplet loss.
The goal is to ensure the model learns effectively by choosing the right combination of examples.</p>
<p>Given the choice of an <code class="docutils literal notranslate"><span class="pre">A</span></code> and a <code class="docutils literal notranslate"><span class="pre">P</span></code>, we denotes by</p>
<ul class="simple">
<li><p><strong>Easy negatives</strong>: the <code class="docutils literal notranslate"><span class="pre">N</span></code>s that are already far from <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p>
<ul>
<li><p>they do not provide much useful information (since the model already distinguishes them well).</p></li>
</ul>
</li>
<li><p><strong>Hard negatives</strong>: the <code class="docutils literal notranslate"><span class="pre">N</span></code>s that are very close to <code class="docutils literal notranslate"><span class="pre">A</span></code>  (even closer than the <code class="docutils literal notranslate"><span class="pre">P</span></code>).</p>
<ul>
<li><p>they are difficult for the model to separate</p></li>
<li><p>this might lead to instability or overfitting.</p></li>
</ul>
</li>
<li><p><strong>Semi-hard negatives</strong>: the <code class="docutils literal notranslate"><span class="pre">N</span></code>s that are farther from <code class="docutils literal notranslate"><span class="pre">A</span></code> than the <code class="docutils literal notranslate"><span class="pre">P</span></code> but still relatively close.</p>
<ul>
<li><p>they provide valuable information  (because they are challenging without being as problematic as hard negatives).</p></li>
</ul>
</li>
</ul>
<p><img alt="triplet-mining" src="_images/brick_tripletmining.png" /><br />
<strong>Figure</strong>
<em>Triplet mining: easy, hard, semi-hard; image source: <a class="reference external" href="https://www.researchgate.net/figure/Online-Triplet-Mining-strategies-For-an-anchor-blue-A-and-a-positive-green-P-sample_fig6_364057028">Link</a></em></p>
<p>We also distinguish between</p>
<ul class="simple">
<li><p><strong>Offline mining</strong>: triplets are <mark>selected prior to training</mark></p>
<ul>
<li><p>may not adapt to the evolving model during training.</p></li>
</ul>
</li>
<li><p><strong>Online mining</strong>: triplets are <mark>selected during training (from the current mini-batch)</mark> using the already learned projection <span class="math notranslate nohighlight">\(f_{\theta}\)</span></p>
<ul>
<li><p>allows selecting the most informative triplets</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="encoder-decoder">
<span id="lab-encoder-decoder"></span><h2>Encoder-Decoder<a class="headerlink" href="#encoder-decoder" title="Permalink to this heading">#</a></h2>
<p><img alt="encoder-decoder" src="_images/brick_enc_dec.png" /></p>
<p><strong>Figure:</strong> Schematic illustration of a canonical autoencoder.</p>
<p>In encoder-decoder methods, such as autoencoders, data is sent through hourglass-like architectures typically possessing a lower-dimensional bottleneck layer.
Such models are trained to minimize a reconstruction error. For example, in the case of autoencoders, the output of the model should be equal to the input.
In order to satisfy this objective, information needs to be “squeezed” through the low-dimensional bottleneck, effectively performing <em>data compression</em>.
The resulting “latent space” tend to be organized in a meaningful way, where similar instances are close and specific data characteristics may correspond to particular directions in the space.</p>
<p>There are different formulations of autoencoder architectures, like <strong>canonical and denoising autoencoders</strong> <span id="id4">[<a class="reference internal" href="bibiography.html#id6" title="Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, volume 307 of ACM International Conference Proceeding Series, 1096–1103. ACM, 2008.">VLBM08</a>]</span>,
as well as <strong>Variational Autoencoders</strong> (VAEs) <span id="id5">[<a class="reference internal" href="bibiography.html#id43" title="Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio and Yann LeCun, editors, 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings. 2014. URL: http://arxiv.org/abs/1312.6114.">KW14</a>]</span>.</p>
<p>Encoder-decoder architectures can also be used in tasks where the output is not trained to be equal to the input, such as <strong>style transfer</strong> or <strong>domain adaptation</strong> (e.g., sequence-to-sequence language translation).
For musical audio, domain adaptation can be achieved by encoding recordings of an instrument or genre type and decoding into another type <span id="id6">[<a class="reference internal" href="bibiography.html#id7" title="Noam Mor, Lior Wolf, Adam Polyak, and Yaniv Taigman. A universal music translation network. In ICLR (Poster). OpenReview.net, 2019.">MWPT19</a>]</span>.</p>
<p>For a more detailed explanation of VAEs in this book, see <a class="reference internal" href="task_musicgeneration_basics.html#lab-vaes"><span class="std std-ref">this link</span></a>.</p>
</section>
<section id="diffusion-models">
<h2>Diffusion Models<a class="headerlink" href="#diffusion-models" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference internal" href="task_musicgeneration_basics.html#lab-diffusion"><span class="std std-ref">this link</span></a>.</p>
</section>
<section id="generative-adversarial-networks">
<h2>Generative Adversarial Networks<a class="headerlink" href="#generative-adversarial-networks" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference internal" href="task_musicgeneration_basics.html#lab-gans"><span class="std std-ref">this link</span></a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bricks_architecture.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Architectures</p>
      </div>
    </a>
    <a class="right-next"
       href="biography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">About the authors</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised">Supervised</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#self-supervised">Self-supervised</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised">Unsupervised</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metric-learning">Metric Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#triplet-loss">Triplet Loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#triplet-mining">Triplet Mining</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoder-decoder">Encoder-Decoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-models">Diffusion Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-adversarial-networks">Generative Adversarial Networks</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Geoffroy Peeters, Gabriel Meseguer-Brocal, Alain Riou, Stefan Lattner
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
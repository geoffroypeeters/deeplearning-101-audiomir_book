

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Basics of Generative Modeling &#8212; Deep Learning 101 for Audio-based MIR</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'task_musicgeneration_basics';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Early Works" href="task_musicgeneration_early.html" />
    <link rel="prev" title="Musical Audio Generation" href="task_musicgeneration.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="front.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/wave.png" class="logo__image only-light" alt="Deep Learning 101 for Audio-based MIR - Home"/>
    <script>document.write(`<img src="_static/wave.png" class="logo__image only-dark" alt="Deep Learning 101 for Audio-based MIR - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="front.html">
                    Deep Learning 101 for Audio-based MIR
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Abstract</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="abstract.html">Abstract</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="intro.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="intro_dataset.html">Datasets .hdf5/.pyjama</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_pytorch.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_lightining.html">TorchLightning training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notebook.html">Notebooks in Colab</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tasks</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="task_musiccontent.html">Music Audio Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="task_multipitchestimation.html">Multi-Pitch-Estimation (MPE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_coverdetection.html">Cover Song Identification (CSI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_autotagging_frontend.html">Auto-Tagging (front-ends)</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_autotagging_ssl.html">Auto-Tagging (self-supervised-learning)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="task_musicprocessing.html">Music Audio Processing</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="task_sourceseparation.html">Source Separation</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="task_musicgeneration.html">Musical Audio Generation</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Basics of Generative Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_early.html">Early Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_auto.html">Autoregressive Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="task_musicgeneration_diff.html">Generation with Latent Diffusion</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning Bricks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bricks_input.html">Inputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_frontend.html">Front-ends</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_projection.html">Projections</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_bottleneck.html">Bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_architecture.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="bricks_paradigm.html">Paradigms</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="biography.html">About the authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibiography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Ftask_musicgeneration_basics.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/task_musicgeneration_basics.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Basics of Generative Modeling</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-generation">Autoregressive Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-autoregressive-parallel-latent-variable-generation">Non-Autoregressive/Parallel/Latent Variable Generation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoders-vaes">Variational Autoencoders (VAEs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-models">Diffusion Models</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="basics-of-generative-modeling">
<h1>Basics of Generative Modeling<a class="headerlink" href="#basics-of-generative-modeling" title="Permalink to this heading">#</a></h1>
<p>In generative tasks, it is necessary to inject <em>some form of stochasticity</em> into the generation process. In this regard, two general approaches can be distinguished: <strong>Autoregressive</strong> generation of <em>discrete sequences</em> and <strong>Non-Autoregressive</strong> (or parallel/latent variable) generation of <em>continuous-valued data</em>.
In this section, we will have a brief look into the two paradigms and give some examples of how they are modeled.</p>
<section id="autoregressive-generation">
<span id="lab-autoregressive"></span><h2>Autoregressive Generation<a class="headerlink" href="#autoregressive-generation" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="generation-autoregressive">
<a class="reference internal image-reference" href="_images/generation_autoregressive.png"><img alt="_images/generation_autoregressive.png" src="_images/generation_autoregressive.png" style="width: 80%;" /></a>
</figure>
<p><strong>Figure 1:</strong> Schematic illustration of autoregressive generation. A sample <span class="math notranslate nohighlight">\( \mathbf{x}_{t+1} \)</span> is generated sequentially based on the conditional distribution <span class="math notranslate nohighlight">\( p(\mathbf{x}_{t+1} | \mathbf{x}_{\leq t}) \)</span>, using all prior samples from the model.</p>
<p>For <strong>discrete sequences</strong>, models such as Recurrent Neural Networks (RNNs) <span id="id1">[<a class="reference internal" href="bibiography.html#id41" title="Jeffrey L. Elman. Finding structure in time. Cogn. Sci., 14(2):179–211, 1990. URL: https://doi.org/10.1207/s15516709cog1402\_1, doi:10.1207/S15516709COG1402\_1.">Elm90</a>]</span>, Causal Convolutional Networks <span id="id2">[<a class="reference internal" href="bibiography.html#id65" title="Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. In Alan W. Black, editor, The 9th ISCA Speech Synthesis Workshop, SSW 2016, Sunnyvale, CA, USA, September 13-15, 2016, 125. ISCA, 2016. URL: https://www.isca-archive.org/ssw\_2016/vandenoord16\_ssw.html.">vdODZ+16</a>]</span>, and Transformers <span id="id3">[<a class="reference internal" href="bibiography.html#id74" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett, editors, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, 5998–6008. 2017. URL: https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.">VSP+17</a>]</span> are typically trained with cross-entropy loss to output a probability distribution over discrete random variables in a deterministic manner. The stochasticity is then “injected” by sampling from that distribution.</p>
<p>At each time step <span class="math notranslate nohighlight">\(t\)</span>, the model outputs a probability distribution <span class="math notranslate nohighlight">\(p(\mathbf{x}_t \mid \mathbf{x}_{&lt;t})\)</span> over the vocabulary <span class="math notranslate nohighlight">\(V\)</span>, conditioned on the previous tokens <span class="math notranslate nohighlight">\(x_{&lt;t}\)</span>. The cross-entropy loss used during training can be expressed as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text{CE}} = -\sum_{t} \log p(\mathbf{x}_t^* \mid \mathbf{x}_{&lt;t})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}_t^*\)</span> is the true token at time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p><strong>Note:</strong> In this case, we can primarily deal with <strong>one-hot encoded sequences</strong>, selecting one token per time step, as we don’t have a simple way to sample <strong>N-hot vectors</strong> (where <span class="math notranslate nohighlight">\(N &gt; 1\)</span> tokens are selected simultaneously) from the model’s output distribution. Sampling multiple tokens at once would require modeling the joint probability of combinations of tokens, which significantly increases complexity and is not commonly addressed in standard sequence generation models.</p>
</section>
<section id="non-autoregressive-parallel-latent-variable-generation">
<span id="lab-parallel"></span><h2>Non-Autoregressive/Parallel/Latent Variable Generation<a class="headerlink" href="#non-autoregressive-parallel-latent-variable-generation" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="generation-parallel">
<a class="reference internal image-reference" href="_images/generation_parallel.png"><img alt="_images/generation_parallel.png" src="_images/generation_parallel.png" style="width: 50%;" /></a>
</figure>
<p><strong>Figure 2:</strong> Schematic illustration of latent variable generation. A sample <span class="math notranslate nohighlight">\( \mathbf{x} \)</span> is generated by transforming <span class="math notranslate nohighlight">\( \mathbf{z} \sim p_z(\mathbf{z}) \)</span> through <span class="math notranslate nohighlight">\( g_\theta \)</span> to match the target distribution <span class="math notranslate nohighlight">\( p(\mathbf{x}) \)</span>.</p>
<p>For generating <strong>continuous-valued data</strong>, the stochasticity usually comes from some form of noise injection into the neural network.
Mathematically, this is typically defined as transforming a simple (usually Gaussian) distribution into the data distribution.
In the following, a brief (architecture-agnostic) introduction in the most common training paradigms is given.</p>
<section id="generative-adversarial-networks-gans">
<span id="lab-gans"></span><h3>Generative Adversarial Networks (GANs)<a class="headerlink" href="#generative-adversarial-networks-gans" title="Permalink to this heading">#</a></h3>
<p>For example, Generative Adversarial Networks (GANs) <span id="id4">[<a class="reference internal" href="bibiography.html#id62" title="Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. Generative adversarial networks. CoRR, 2014. URL: http://arxiv.org/abs/1406.2661, arXiv:1406.2661.">GPougetAbadieM+14</a>]</span> in their basic form inject noise by inputting a high-dimensional noise vector
<span class="math notranslate nohighlight">\(\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</span> (sampled from an independent Gaussian distribution) into the generator <span class="math notranslate nohighlight">\(G\)</span>.
The generator transforms this noise vector into a data sample: <span class="math notranslate nohighlight">\(\mathbf{x} = G(\mathbf{z})\)</span>.
Thus, the task can be described as learning to transform an independent Gaussian distribution into the data distribution.</p>
<p>The generator is trained by playing an adversarial game with a discriminator <span class="math notranslate nohighlight">\(D\)</span>.
The discriminator aims to distinguish between real samples from the dataset and fake samples generated by <span class="math notranslate nohighlight">\(G\)</span>.
The generator is trained to produce samples that maximize the likelihood of fooling the discriminator.
This can be formalized by the minimax game between <span class="math notranslate nohighlight">\(G\)</span> and <span class="math notranslate nohighlight">\(D\)</span></p>
<div class="math notranslate nohighlight">
\[
\min_G \max_D V(D, G) = \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}} [\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p(\mathbf{z})} [\log (1 - D(G(\mathbf{z})))]
\]</div>
<p>where <span class="math notranslate nohighlight">\(p(\mathbf{z})\)</span> represents the distribution of noise input.
This adversarial setup ensures that as <span class="math notranslate nohighlight">\(D\)</span> improves in distinguishing real from fake data,
<span class="math notranslate nohighlight">\(G\)</span> improves in generating more realistic samples, ultimately leading to convergence when the generated data becomes indistinguishable from the real data.</p>
</section>
<section id="variational-autoencoders-vaes">
<span id="lab-vaes"></span><h3>Variational Autoencoders (VAEs)<a class="headerlink" href="#variational-autoencoders-vaes" title="Permalink to this heading">#</a></h3>
<p>Similarly, in Variational Autoencoders (VAEs, composed of encoder and decoder) <span id="id5">[<a class="reference internal" href="bibiography.html#id43" title="Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio and Yann LeCun, editors, 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings. 2014. URL: http://arxiv.org/abs/1312.6114.">KW14</a>]</span>, the decoder receives as input a sample from an independent Gaussian prior distribution (a “standard normal distribution”).
The model is trained so that the encoder learns to approximate the prior using a mixture of Gaussian posteriors, one for each data point:
<span class="math notranslate nohighlight">\(\boldsymbol{\mu}, \boldsymbol{\sigma} = E(\mathbf{x})\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\sigma}\)</span> are multi-dimensional mean and variance vectors.
From this posterior, we sample a latent variable <span class="math notranslate nohighlight">\(\mathbf{z} \sim q_{\phi}(\mathbf{z} \mid \mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma})\)</span> during training.
The decoder then reconstructs the input by transforming <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> into a data point <span class="math notranslate nohighlight">\(\hat{\mathbf{x}} = D(\mathbf{z})\)</span>.</p>
<p>Training involves minimizing two objectives: the reconstruction loss between <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathbf{x}}\)</span>, and the Kullback-Leibler (KL) divergence
between the learned posterior <span class="math notranslate nohighlight">\(q_{\phi}(\mathbf{z} \mid \mathbf{x})\)</span> and the prior distribution <span class="math notranslate nohighlight">\(p(\mathbf{z}) \sim \mathcal{N}(0, I)\)</span>.
The two objectives are adversarial because the KL term pushes the posteriors towards a zero mean and unit variance, while the reconstruction term encourages the posteriors to adopt distinct means and reduced variances, allowing each data point to have its own distribution.
Together, they make it possible to sample from the prior <span class="math notranslate nohighlight">\(p(\mathbf{z}) \sim \mathcal{N}(0, I)\)</span> at inference and decoding it into a plausible data sample: <span class="math notranslate nohighlight">\(\hat{\mathbf{x}} = D(\mathbf{z})\)</span>.</p>
</section>
<section id="diffusion-models">
<span id="lab-diffusion"></span><h3>Diffusion Models<a class="headerlink" href="#diffusion-models" title="Permalink to this heading">#</a></h3>
<p>In Diffusion Models <span id="id6">[<a class="reference internal" href="bibiography.html#id42" title="Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. 2020. URL: https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html.">HJA20</a>]</span>, the noise input has the same dimensionality as the data point that should be generated.
The model gradually transforms noise into data through a series of steps.
Like before, the goal is to transform a Gaussian prior distribution into the data distribution through the learned denoising steps.
In its initial form it is defined as a Markov chain with learned Gaussian transitions starting at <span class="math notranslate nohighlight">\(p(\mathbf{x}_T) = \mathcal{N}(\mathbf{x}_T; \mathbf{0}, \mathbf{I})\)</span>.
The model learns to reverse the noising process by estimating <span class="math notranslate nohighlight">\(p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
   p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_{\theta}(\mathbf{x}_t, t), \sigma_t^2 \mathbf{I}).
   \]</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="task_musicgeneration.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Musical Audio Generation</p>
      </div>
    </a>
    <a class="right-next"
       href="task_musicgeneration_early.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Early Works</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-generation">Autoregressive Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-autoregressive-parallel-latent-variable-generation">Non-Autoregressive/Parallel/Latent Variable Generation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoders-vaes">Variational Autoencoders (VAEs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-models">Diffusion Models</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Geoffroy Peeters, Gabriel Meseguer-Brocal, Alain Riou, Stefan Lattner
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>